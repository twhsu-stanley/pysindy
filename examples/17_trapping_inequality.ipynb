{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Trapping SINDy\n",
    "By Alan Kaptanoglu\n",
    "\n",
    "A very common issue is that models identified by system identification methods typically have no guarantees that the models are numerically or physically stable. This can be addressed with heuristic, data-driven, or analytic closure models, but we have recently directly promoted globally stable models into the system identification itself (see the Example 8 Jupyter notebook). This is really nice but there are three potential caveats, (1) the regression is nonconvex and there a number of hyperparameters, so this method can be difficult to learn, and (2) in order to promote global stability, one needs an analytic result from stability theory, and the one we use applies only for quadratically nonlinear dynamics (typically fluid and plasma flows) with energy-preserving, quadratic, nonlinearities. Moreover, we have now (3) additionally shown that generic quadratically nonlinear models will always be globally *unbounded*, so for these situations we can also promote local Lyapunov stability of the origin using some variations of the original Trapping SINDy algorithm. That is the goal of this notebook -- to illustrate how various forms of global and local stability can be promoted explicitly in the SINDy method to obtain stable data-driven models.\n",
    "\n",
    "For the following, we will consider dynamical models of the form\n",
    "$$\\dot{x}_i = C_i +  L_{ij}x_j + Q_{ijk}x_ix_j.$$\n",
    "For global stability promotion, we will require skew-symmetry in the quadratic coefficients\n",
    "$$ Q_{ijk} + Q_{jik} + Q_{kij} = 0.$$\n",
    "This equation will be implemented as a hard constraint in the optimization. However, for dynamical models that do not satisfy this condition, we can still promote locally stable models that are stable even at fairly large distances of the origin. The following examples show different ways to relax this hard constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pysindy as ps \n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.io as sio\n",
    "from pysindy.utils import lorenz\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some setup and plotting functions\n",
    "# Build the skew-symmetric nonlinearity constraints\n",
    "def make_constraints(r):\n",
    "    q = 0\n",
    "    N = int((r ** 2 + 3 * r) / 2.0) + 1  # + 1 for constant term\n",
    "    p = r + r * (r - 1) + int(r * (r - 1) * (r - 2) / 6.0)\n",
    "    constraint_zeros = np.zeros(p)\n",
    "    constraint_matrix = np.zeros((p, r * N))    \n",
    "    \n",
    "    # Set coefficients adorning terms like a_i^3 to zero\n",
    "    # [1, x, y, z, xy, xz, yz, x2, y2, z2, 1, ...]\n",
    "    # [1 1 1 x x x y y y ...]\n",
    "    for i in range(r):\n",
    "        # constraint_matrix[q, r * (N - r) + i * (r + 1)] = 1.0\n",
    "        constraint_matrix[q, r * (N - r) + i * (r + 1)] = 3.0\n",
    "        q = q + 1\n",
    "\n",
    "    # Set coefficients adorning terms like a_ia_j^2 to be antisymmetric\n",
    "    for i in range(r):\n",
    "        for j in range(i + 1, r):\n",
    "            constraint_matrix[q, r * (N - r + j) + i] = 1.0\n",
    "            constraint_matrix[q, r + r * (r + j - 1) + j + r * int(i * (2 * r - i - 3) / 2.0)] = 1.0\n",
    "            q = q + 1\n",
    "    for i in range(r):\n",
    "         for j in range(0, i):\n",
    "            constraint_matrix[q, r * (N - r + j) + i] = 1.0\n",
    "            constraint_matrix[q, r + r * (r + i - 1) + j + r * int(j * (2 * r - j - 3) / 2.0)] = 1.0\n",
    "            q = q + 1\n",
    "\n",
    "    # Set coefficients adorning terms like a_ia_ja_k to be antisymmetric\n",
    "    for i in range(r):\n",
    "        for j in range(i + 1, r):\n",
    "            for k in range(j + 1, r):\n",
    "                constraint_matrix[q, r + r * (r + k - 1) + i + r * int(j * (2 * r - j - 3) / 2.0)] = 1 / 2.0\n",
    "                constraint_matrix[q, r + r * (r + k - 1) + j + r * int(i * (2 * r - i - 3) / 2.0)] = 1 / 2.0\n",
    "                constraint_matrix[q, r + r * (r + j - 1) + k + r * int(i * (2 * r - i - 3) / 2.0)] = 1 / 2.0\n",
    "                q = q + 1\n",
    "\n",
    "    return constraint_zeros, constraint_matrix\n",
    "\n",
    "\n",
    "# Use optimal m, and calculate eigenvalues(PW) to see if identified model is stable\n",
    "def check_stability(r, Xi, mod_matrix, sindy_opt, mean_val):\n",
    "    opt_m = sindy_opt.m_history_[-1]\n",
    "    PC_tensor = sindy_opt.PC_\n",
    "    PL_tensor_unsym = sindy_opt.PL_unsym_\n",
    "    PL_tensor = sindy_opt.PL_\n",
    "    PM_tensor = sindy_opt.PM_\n",
    "    PQ_tensor = sindy_opt.PQ_\n",
    "    mPM = np.tensordot(PM_tensor, opt_m, axes=([2], [0]))\n",
    "    P_tensor = PL_tensor + mPM\n",
    "    As = np.tensordot(P_tensor, Xi, axes=([3, 2], [0, 1]))\n",
    "    As = mod_matrix @ As\n",
    "    eigvals, eigvecs = np.linalg.eigh(As)\n",
    "    print('optimal m: ', opt_m)\n",
    "    print('As eigvals: ', np.sort(eigvals))\n",
    "    max_eigval = np.sort(eigvals)[-1]\n",
    "    min_eigval = np.sort(eigvals)[0]\n",
    "    C = np.tensordot(PC_tensor, Xi, axes=([2, 1], [0, 1]))\n",
    "    L = np.tensordot(PL_tensor_unsym, Xi, axes=([3, 2], [0, 1]))\n",
    "    Q = np.tensordot(PQ_tensor, Xi, axes=([4, 3], [0, 1]))\n",
    "    d = C + np.dot(L, opt_m) + np.dot(np.tensordot(Q, opt_m, axes=([2], [0])), opt_m)\n",
    "    d = mod_matrix @ d\n",
    "    Rm = np.linalg.norm(d) / np.abs(max_eigval)\n",
    "    Reff = Rm / mean_val\n",
    "    print('Estimate of trapping region size, Rm = ', Rm)\n",
    "    print('Normalized trapping region size, Reff = ', Reff)\n",
    "\n",
    "\n",
    "# use optimal m, calculate and plot the stability radius when the third-order\n",
    "# energy-preserving scheme slightly breaks\n",
    "def make_DA_progress_plots(r, mod_matrix, sindy_opt):\n",
    "    PC_tensor = sindy_opt.PC_\n",
    "    PL_tensor_unsym = sindy_opt.PL_unsym_\n",
    "    PQ_tensor = sindy_opt.PQ_\n",
    "    ms = sindy_opt.m_history_\n",
    "    eigs = sindy_opt.PWeigs_history_\n",
    "    coef_history = sindy_opt.history_\n",
    "    rhos = []\n",
    "    for i in range(len(eigs)):\n",
    "        if eigs[i][-1] < 0:\n",
    "            # Q = np.tensordot(sindy_opt.PQ_, coef_history[i], axes=([4, 3], [1, 0]))\n",
    "            # Q_sum = Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])\n",
    "            C = np.tensordot(PC_tensor, coef_history[i], axes=([2, 1], [1, 0]))\n",
    "            L = np.tensordot(PL_tensor_unsym, coef_history[i], axes=([3, 2], [1, 0]))\n",
    "            Q = np.tensordot(PQ_tensor, coef_history[i], axes=([4, 3], [1, 0]))\n",
    "            Q_sum = np.max(np.abs((Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1]))))\n",
    "            d = C + np.dot(L, ms[i]) + np.dot(np.tensordot(Q, ms[i], axes=([2], [0])), ms[i])\n",
    "            d = mod_matrix @ d\n",
    "            eps_Q = np.max(np.abs(Q_sum))\n",
    "            Rm = (3 / (2 * np.sqrt(r ** 2) * eps_Q)) \\\n",
    "                    * (np.sqrt(eigs[i][-1] ** 2 - 4 * np.sqrt(r ** 3)\\\n",
    "                               * eps_Q * np.linalg.norm(d, 2)/3) - eigs[i][-1])\n",
    "            if Rm > 0:\n",
    "                rhos.append(Rm)\n",
    "            else:\n",
    "                rhos.append(0)\n",
    "            # rhos.append(-eigs[i][-1] / np.max(np.abs(Q_sum)))\n",
    "    print(np.linalg.norm(d, 2))\n",
    "    plt.plot(rhos[1:])\n",
    "    plt.grid(True)\n",
    "    plt.ylabel('Stability radius')\n",
    "    plt.xlabel('Algorithm iteration')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot first three modes in 3D for ground truth and SINDy prediction\n",
    "def make_3d_plots(x_test, x_test_pred, filename):\n",
    "    fig, ax = plt.subplots(1, 1, subplot_kw={'projection': '3d'}, figsize=(8, 8))\n",
    "    plt.plot(x_test[:, 0], x_test[:, 1], x_test[:, 2], \n",
    "             'r', label='true x')\n",
    "    plt.plot(x_test_pred[:, 0], x_test_pred[:, 1], x_test_pred[:, 2], \n",
    "             'k', label='pred x')\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    ax.set_axis_off()\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the SINDy fits of X and Xdot against the ground truth\n",
    "def make_fits(r, t, xdot_test, xdot_test_pred, x_test, x_test_pred, filename):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    spec = gridspec.GridSpec(ncols=2, nrows=r, figure=fig, hspace=0.0, wspace=0.0)\n",
    "    for i in range(r):\n",
    "        plt.subplot(spec[i, 0]) #r, 2, 2 * i + 2)\n",
    "        plt.plot(t, xdot_test[:, i], 'r', \n",
    "                 label=r'true $\\dot{x}_' + str(i) + '$')\n",
    "        plt.plot(t, xdot_test_pred[:, i], 'k--', \n",
    "                 label=r'pred $\\dot{x}_' + str(i) + '$')\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        plt.legend(fontsize=12)\n",
    "        if i == r - 1:\n",
    "            plt.xlabel('t', fontsize=18)\n",
    "        plt.subplot(spec[i, 1])\n",
    "        plt.plot(t, x_test[:, i], 'r', label=r'true $x_' + str(i) + '$')\n",
    "        plt.plot(t, x_test_pred[:, i], 'k--', label=r'pred $x_' + str(i) + '$')\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        plt.legend(fontsize=12)\n",
    "        if i == r - 1:\n",
    "            plt.xlabel('t', fontsize=18)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Plot errors between m_{k+1} and m_k and similarly for the model coefficients\n",
    "def make_progress_plots(r, sindy_opt):\n",
    "    W = np.asarray(sindy_opt.history_)\n",
    "    M = np.asarray(sindy_opt.m_history_)\n",
    "    dW = np.zeros(W.shape[0])\n",
    "    dM = np.zeros(M.shape[0])\n",
    "    for i in range(1,W.shape[0]):\n",
    "        dW[i] = np.sum((W[i, :, :] - W[i - 1, :, :]) ** 2)\n",
    "        dM[i] = np.sum((M[i, :] - M[i - 1, :]) ** 2)\n",
    "    plt.figure()\n",
    "    plt.semilogy(dW, label=r'Coefficient progress, $\\|\\xi_{k+1} - \\xi_k\\|_2^2$')\n",
    "    plt.semilogy(dM, label=r'Vector m progress, $\\|m_{k+1} - m_k\\|_2^2$')\n",
    "    plt.xlabel('Algorithm iterations', fontsize=16)\n",
    "    plt.ylabel('Errors', fontsize=16)\n",
    "    plt.legend(fontsize=14)\n",
    "    PWeigs = np.asarray(sindy_opt.PWeigs_history_)\n",
    "    plt.figure()\n",
    "    for j in range(r):\n",
    "        if np.all(PWeigs[:, j] > 0.0):\n",
    "            plt.semilogy(PWeigs[:, j], \n",
    "                         label=r'diag($P\\xi)_{' + str(j) + str(j) + '}$')\n",
    "        else:\n",
    "            plt.plot(PWeigs[:, j], \n",
    "                     label=r'diag($P\\xi)_{' + str(j) + str(j) + '}$')\n",
    "        plt.xlabel('Algorithm iterations', fontsize=16)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.ylabel(r'Eigenvalues of $P\\xi$', fontsize=16)\n",
    "\n",
    "# Initialize quadratic SINDy library, with custom ordering \n",
    "# to be consistent with the constraint\n",
    "library_functions = [lambda x:x, lambda x, y:x * y, lambda x:x ** 2]\n",
    "library_function_names = [lambda x:x, lambda x, y:x + y, lambda x:x + x]\n",
    "sindy_library = ps.CustomLibrary(library_functions=library_functions, \n",
    "                                 function_names=library_function_names,\n",
    "                                 include_bias=True)\n",
    "\n",
    "# Initialize integrator keywords for solve_ivp to replicate the odeint defaults\n",
    "integrator_keywords = {}\n",
    "integrator_keywords['rtol'] = 1e-15\n",
    "integrator_keywords['method'] = 'LSODA'\n",
    "integrator_keywords['atol'] = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lorenz model\n",
    "The Lorenz system originates from a simple fluid model of atmospheric dynamics from Lorenz et al. (1963).\n",
    "This system is likely the most famous example of chaotic, nonlinear behavior despite the somewhat innocuous system of equations,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{d}{dt}\\begin{bmatrix}\n",
    "    x \\\\ \n",
    "    y \\\\\n",
    "    z \\\\\n",
    "    \\end{bmatrix} &= \\begin{bmatrix}\n",
    "    -\\sigma & \\sigma & 0 \\\\\n",
    "    \\rho & -1 & 0 \\\\\n",
    "    0 & 0 & -\\beta\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "    z\n",
    "    \\end{bmatrix}\n",
    "    +\n",
    "    \\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    -xz \\\\\n",
    "    xy\n",
    "    \\end{bmatrix}, \\qquad\n",
    "    \\mathbf{A}^S = \\begin{bmatrix}\n",
    "    -\\sigma & \\frac{1}{2}(\\rho+\\sigma - m_3) & \\frac{1}{2}m_2 \\\\\n",
    "    \\frac{1}{2}(\\rho+\\sigma - m_3) & -1 & 0 \\\\\n",
    "    \\frac{1}{2}m_2 & 0 & -\\beta \n",
    "    \\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For Lorenz's choice of parameters, $\\sigma = 10$, $\\rho = 28$, $\\beta  = 8/3$, this system is known to exhibit a stable attractor. For $\\mathbf{m} = [0,m_2,\\rho+\\sigma]$ ($m_1$ does not contribute to $\\mathbf{A}^S$ so we set it to zero),\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{A}^S &= \\begin{bmatrix}\n",
    "    -\\sigma & 0 & \\frac{1}{2}m_2 \\\\\n",
    "    0 & -1 & 0 \\\\\n",
    "    \\frac{1}{2}m_2 & 0 & -\\beta \n",
    "    \\end{bmatrix}, \\qquad\n",
    "    \\lambda_1 = -1, \\qquad \\lambda_{\\pm} = -\\frac{1}{2}\\left[\\beta+\\sigma \\mp \\sqrt{m_2^2 + (\\beta-\\sigma)^2}\\right],\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "so that if $\\lambda_{\\pm} < 0$, then $-2\\sqrt{\\sigma\\beta} < m_2 < 2\\sqrt{\\sigma\\beta}$. \n",
    "Our algorithm can successfully identify the optimal $\\mathbf{m}$, and can be used to identify the inequality bounds on $m_2$ for stability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check global stability of the Lorenz model\n",
    "The skew-symmetric models below are globally stable *if and only if* there exists a vector $\\mathbf{m}$ such that following matrix is negative definite:\n",
    "$$A^S_{ij} = L^S_{ij} + (Q_{ijk} + Q_{jik})m_k.$$\n",
    "Note that if the quadratic terms are skew-symmetric this is equal to\n",
    "$$A^S_{ij} = L^S_{ij} - Q_{kij}m_k.$$\n",
    "A negative definite $\\mathbf{A}^S$ turns out to also be necessary for the non-skew-symmetric models, but in this case is not sufficient for global boundedness.\n",
    "\n",
    "A good algorithm for a nonlinear search for a good $\\mathbf{m}$ is simulated annealing, and a simple interface is provided by scipy. We show below that the models that are exactly skew-symmetric are globally stable, and the models that (weakly) break this constraint are not. This is true whether or not we consider the energy, enstrophy, or some other positive definite function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter ... |y-Xw|^2 ... |Pw-A|^2/eta ... |w|_1 ... |Qijk|/a ... |Qijk+...|/b ...   Total:\n",
      "    0 ... 6.342e+02 ... 1.273e-03 ... 0.00e+00 ... 4.94e-21 ... 4.49e-47 ... 6.34e+02\n",
      "  200 ... 6.342e+02 ... 3.772e-06 ... 0.00e+00 ... 4.94e-21 ... 2.97e-47 ... 6.34e+02\n",
      "  400 ... 6.342e+02 ... 5.981e-07 ... 0.00e+00 ... 4.94e-21 ... 2.55e-47 ... 6.34e+02\n",
      "  600 ... 6.342e+02 ... 2.261e-07 ... 0.00e+00 ... 4.94e-21 ... 8.70e-48 ... 6.34e+02\n",
      "  800 ... 6.342e+02 ... 1.185e-07 ... 0.00e+00 ... 4.94e-21 ... 5.21e-47 ... 6.34e+02\n",
      " 1000 ... 6.342e+02 ... 7.348e-08 ... 0.00e+00 ... 4.94e-21 ... 3.09e-47 ... 6.34e+02\n",
      " 1200 ... 6.342e+02 ... 5.049e-08 ... 0.00e+00 ... 4.94e-21 ... 1.07e-46 ... 6.34e+02\n",
      " 1400 ... 6.342e+02 ... 3.715e-08 ... 0.00e+00 ... 4.94e-21 ... 1.12e-47 ... 6.34e+02\n",
      " 1600 ... 6.342e+02 ... 2.871e-08 ... 0.00e+00 ... 4.94e-21 ... 9.78e-48 ... 6.34e+02\n",
      " 1800 ... 6.342e+02 ... 2.301e-08 ... 0.00e+00 ... 4.94e-21 ... 7.50e-47 ... 6.34e+02\n",
      "(x0)' = -0.010 1 + -9.886 x0 + 9.945 x1 + -0.002 x0x2\n",
      "(x1)' = -0.047 1 + 27.786 x0 + -0.929 x1 + 0.006 x2 + -0.994 x0x2 + -0.001 x1x2\n",
      "(x2)' = 0.070 1 + -0.002 x0 + -0.001 x1 + -2.663 x2 + 0.993 x0x1 + 0.002 x0x0 + 0.001 x1x1\n",
      "2.0988853016712383e-14\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "r = 3\n",
    "N = int((r ** 2 + 3 * r) / 2.0)\n",
    "# make training and testing data\n",
    "dt = 0.01\n",
    "T = 100\n",
    "t = np.arange(0, T + dt, dt)\n",
    "t_span = (t[0], t[-1])\n",
    "x0 = [1, -1, 20]\n",
    "x_train = solve_ivp(lorenz, t_span, x0, t_eval=t, **integrator_keywords).y.T\n",
    "x0 = (np.random.rand(3) - 0.5) * 30\n",
    "x_test = solve_ivp(lorenz, t_span, x0, t_eval=t, **integrator_keywords).y.T\n",
    "\n",
    "# define hyperparameters\n",
    "threshold = 0\n",
    "max_iter = 2000\n",
    "eta = 1.0e5\n",
    "\n",
    "# See below code if using threshold !=0\n",
    "# if threshold != 0:\n",
    "#     max_iter = 1000\n",
    "#     eta = 1.0e-1\n",
    "constraint_zeros, constraint_matrix = make_constraints(r)\n",
    "\n",
    "alpha_m = 2e-1 * eta  # default is 1e-2 * eta so this speeds up the code here\n",
    "accel = True  # use acceleration for the update of (m, A), sometimes is faster\n",
    "\n",
    "# run trapping SINDy\n",
    "sindy_opt = ps.TrappingSR3(threshold=threshold, eta=eta, alpha_m=alpha_m,\n",
    "                           accel=accel, max_iter=max_iter, gamma=-1,\n",
    "                           constraint_lhs=constraint_matrix,\n",
    "                           constraint_rhs=constraint_zeros,\n",
    "                           constraint_order=\"feature\",\n",
    "                           verbose=True\n",
    "                           )\n",
    "model = ps.SINDy(\n",
    "    optimizer=sindy_opt,\n",
    "    feature_library=sindy_library,\n",
    ")\n",
    "model.fit(x_train, t=t, quiet=True)\n",
    "model.print()\n",
    "\n",
    "Xi = model.coefficients().T\n",
    "PL_tensor = sindy_opt.PL_unsym_\n",
    "PQ_tensor = sindy_opt.PQ_\n",
    "Lenergy = np.tensordot(PL_tensor, Xi, axes=([3, 2], [0, 1]))\n",
    "Q = np.tensordot(PQ_tensor, Xi, axes=([4, 3], [0, 1]))\n",
    "# Q = np.tensordot(sindy_opt.PQ_, Xi, axes=([4, 3], [0, 1]))\n",
    "print(np.max(np.abs((Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01035564 -0.04653326  0.06996161]\n",
      "[[-9.88642267e+00  9.94530209e+00  2.59543488e-04]\n",
      " [ 2.77857505e+01 -9.29153348e-01  5.71170926e-03]\n",
      " [-2.22472703e-03 -9.38930339e-04 -2.66281875e+00]]\n",
      "[[[-1.06608970e-16 -4.95229158e-05 -1.16126427e-03]\n",
      "  [-4.95229158e-05  1.05991144e-04  1.91854475e-04]\n",
      "  [-1.16126427e-03  1.91854475e-04 -3.06868220e-06]]\n",
      "\n",
      " [[ 9.90458316e-05 -5.29955721e-05 -4.96861470e-01]\n",
      "  [-5.29955721e-05 -1.11022302e-16 -6.97113463e-04]\n",
      "  [-4.96861470e-01 -6.97113463e-04 -1.29248127e-04]]\n",
      "\n",
      " [[ 2.32252853e-03  4.96669616e-01  1.53434110e-06]\n",
      "  [ 4.96669616e-01  1.39422693e-03  6.46240637e-05]\n",
      "  [ 1.53434110e-06  6.46240637e-05  3.38964967e-15]]]\n"
     ]
    }
   ],
   "source": [
    "# Check C, L, and Q are correct\n",
    "print(Xi[0, :])\n",
    "print(Lenergy)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xdot_test = model.differentiate(x_test, t=t)\n",
    "xdot_test_pred = model.predict(x_test)\n",
    "x_train_pred = model.simulate(x_train[0, :], t, integrator_kws=integrator_keywords)\n",
    "x_test_pred = model.simulate(x_test[0, :], t, integrator_kws=integrator_keywords)\n",
    "\n",
    "# plotting and analysis\n",
    "make_fits(r, t, xdot_test, xdot_test_pred, x_test, x_test_pred, 'lorenz')\n",
    "make_3d_plots(x_test, x_test_pred, 'lorenz')\n",
    "make_progress_plots(r, sindy_opt)\n",
    "mean_val = np.mean(x_test_pred, axis=0)\n",
    "mean_val = np.sqrt(np.sum(mean_val ** 2))\n",
    "check_stability(r, Xi, np.eye(r), sindy_opt, mean_val)\n",
    "E_pred = np.linalg.norm(x_test - x_test_pred) / np.linalg.norm(x_test)\n",
    "print('Frobenius error = ', E_pred)\n",
    "\n",
    "# compute relative Frobenius error in the model coefficients\n",
    "sigma = 10\n",
    "rho = 28\n",
    "beta = 8.0 / 3.0\n",
    "Xi_lorenz = np.zeros(Xi.shape)\n",
    "Xi_lorenz[:r, :r] = np.asarray([[-sigma, sigma, 0], [rho, -1, 0], [0, 0, -beta]]).T\n",
    "Xi_lorenz[r + 1, 1] = -1\n",
    "Xi_lorenz[r, 2] = 1\n",
    "coef_pred = np.linalg.norm(Xi_lorenz - Xi) / np.linalg.norm(Xi_lorenz)\n",
    "print('Frobenius coefficient error = ', coef_pred)\n",
    "\n",
    "# Compute time-averaged dX/dt error\n",
    "deriv_error = np.zeros(xdot_test.shape[0])\n",
    "for i in range(xdot_test.shape[0]):\n",
    "    deriv_error[i] = np.dot(xdot_test[i, :] - xdot_test_pred[i, :], \n",
    "                            xdot_test[i, :] - xdot_test_pred[i, :])  / np.dot(\n",
    "                            xdot_test[i, :], xdot_test[i, :])\n",
    "print('Time-averaged derivative error = ', np.nanmean(deriv_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import simulated annealing algorithm from scipy\n",
    "from scipy.optimize import dual_annealing as anneal_algo\n",
    "\n",
    "# define the objective function to be minimized by simulated annealing\n",
    "def obj_function(m, L_obj, Q_obj, P_obj):\n",
    "    mQ_full = np.tensordot(Q_obj, m, axes=([2], [0]))\n",
    "    As = L_obj + P_obj @ mQ_full\n",
    "    eigvals, eigvecs = np.linalg.eigh(As)\n",
    "    return(eigvals[-1])\n",
    "\n",
    "boundvals = np.zeros((r, 2))\n",
    "boundmax = 1000\n",
    "boundmin = -1000\n",
    "boundvals[:, 0] = boundmin\n",
    "boundvals[:, 1] = boundmax\n",
    "\n",
    "PL_tensor_unsym = sindy_opt.PL_unsym_\n",
    "PL_tensor = sindy_opt.PL_\n",
    "PM_tensor = sindy_opt.PM_\n",
    "L = np.tensordot(PL_tensor, Xi, axes=([3, 2], [0, 1]))\n",
    "Q = np.tensordot(PM_tensor, Xi, axes=([4, 3], [0, 1]))\n",
    "# run simulated annealing \n",
    "algo_sol = anneal_algo(obj_function, bounds=boundvals, \n",
    "                       args=(L, Q, np.eye(r)), \n",
    "                       maxiter=500)\n",
    "opt_m = algo_sol.x\n",
    "opt_energy = algo_sol.fun\n",
    "opt_result = algo_sol.message\n",
    "print('Result:')\n",
    "print('Optimal m = ', opt_m)\n",
    "print('Algorithm managed to reduce the largest eigenvalue of A^S to eig1 = ', \n",
    "      opt_energy, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoting locally stable models with estimates of the stability radius\n",
    "So far, we have promoted globally stable models with trapping SINDy by enforcing the skew-symmetry structure in the nonlinearities as a hard constraint in the optimization problem:\n",
    "$$ argmin_{\\mathbf{\\xi},\\mathbf m}\\|\\dot{\\mathbf a} - \\mathbf \\Theta(\\mathbf a) \\mathbf{\\xi}\\|^2 + \\gamma R(\\mathbf \\xi)  + \\eta \\lambda_1(\\mathbf A)  \\quad s.t. \\quad Q_{ijk} + Q_{jik} + Q_{kji} = 0.$$\n",
    "This problem is solved with a convex relaxation. Below, we relax the hard constraint slightly and instead solve \n",
    "$$ argmin_{\\mathbf{\\xi},\\mathbf m}\\|\\dot{\\mathbf a} - \\mathbf \\Theta(\\mathbf a) \\mathbf{\\xi}\\|^2 + \\gamma R(\\mathbf \\xi)  + \\eta \\lambda_1(\\mathbf A)  \\quad s.t. \\quad -\\epsilon_Q \\leq Q_{ijk} + Q_{jik} + Q_{kji} \\leq \\epsilon_Q.$$ \n",
    "This allows us to build locally Lyapunov stable models, and adjust the size of the local stability radius by varying $\\epsilon_Q$. A conservative estimate of the local stability is:\n",
    "$$\\rho = \\frac{\\lambda_1(\\mathbf A^S)}{2\\epsilon_Q}.$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoting locally stable models with estimates of the stability radius\n",
    "So far, we have promoted globally stable models with trapping SINDy by enforcing the skew-symmetry structure in the nonlinearities as a hard constraint in the optimization problem:\n",
    "$$ argmin_{\\mathbf{\\xi},\\mathbf m}\\|\\dot{\\mathbf a} - \\mathbf \\Theta(\\mathbf a) \\mathbf{\\xi}\\|^2 + \\gamma R(\\mathbf \\xi)  + \\eta \\lambda_1(\\mathbf A)  \\quad s.t. \\quad Q_{ijk} + Q_{jik} + Q_{kji} = 0.$$\n",
    "This problem is solved with a convex relaxation. Below, we relax the hard constraint slightly and instead solve \n",
    "$$ argmin_{\\mathbf{\\xi},\\mathbf m}\\|\\dot{\\mathbf a} - \\mathbf \\Theta(\\mathbf a) \\mathbf{\\xi}\\|^2 + \\gamma R(\\mathbf \\xi)  + \\eta \\lambda_1(\\mathbf A)  \\quad s.t. \\quad -\\epsilon_Q \\leq Q_{ijk} + Q_{jik} + Q_{kji} \\leq \\epsilon_Q.$$ \n",
    "This allows us to build locally Lyapunov stable models, and adjust the size of the local stability radius by varying $\\epsilon_Q$. A conservative estimate of the local stability is:\n",
    "$$\\rho = \\frac{3}{2r^{\\frac{3}{2}}\\epsilon_Q} \\left( \\sqrt{\\lambda^2_{\\text{max}}(\\textbf{A}_S) - \\frac{4r^{\\frac{3}{2}}\\epsilon_Q}{3}\\|d\\|_2} - \\lambda_{\\text{max}}(\\textbf{A}_S) \\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 400\n",
    "eta = 1e2\n",
    "threshold = 1.0\n",
    "alpha_m = 5e-1 * eta\n",
    "eps_Q = 1e-2\n",
    "gamma = -0.1\n",
    "\n",
    "# Setup the inequality constraints\n",
    "constraint_zeros, constraint_matrix = make_constraints(r)\n",
    "constraint_zeros_extended = np.ones(len(constraint_zeros) * 2) * eps_Q\n",
    "constraint_zeros_extended[len(constraint_zeros):] = eps_Q\n",
    "constraint_matrix_extended = np.zeros((len(constraint_zeros) * 2, constraint_matrix.shape[-1]))\n",
    "constraint_matrix_extended[:len(constraint_zeros), :] = constraint_matrix\n",
    "constraint_matrix_extended[len(constraint_zeros):, :] = -constraint_matrix\n",
    "\n",
    "# run trapping SINDy\n",
    "sindy_opt = ps.TrappingSR3(\n",
    "    threshold=threshold, eta=eta,\n",
    "    alpha_m=alpha_m, gamma=gamma,\n",
    "    max_iter=max_iter,\n",
    "    constraint_lhs=constraint_matrix_extended,\n",
    "    constraint_rhs=constraint_zeros_extended,\n",
    "    constraint_order=\"feature\",\n",
    "    verbose=True,\n",
    "    # verbose_cvxpy=True,\n",
    "    inequality_constraints=True,\n",
    "    eps_solver=1e-3\n",
    ")\n",
    "model = ps.SINDy(\n",
    "    optimizer=sindy_opt,\n",
    "    feature_library=sindy_library,\n",
    ")\n",
    "model.fit(x_train, t=t)\n",
    "model.print()\n",
    "Xi = model.coefficients().T\n",
    "PL_tensor = sindy_opt.PL_\n",
    "PQ_tensor = sindy_opt.PQ_\n",
    "mean_val = np.mean(x_test_pred, axis=0)\n",
    "mean_val = np.sqrt(np.sum(mean_val ** 2))\n",
    "check_stability(r, Xi, np.eye(r), sindy_opt, mean_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check inequality constraints are working!\n",
    "Note that this may fail if the CVXPY solver error tolerance is too low. In that case, increase the value of eps_solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.tensordot(sindy_opt.PQ_, Xi, axes=([4, 3], [0, 1]))\n",
    "print(np.max(Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot how the local stability radius changes as the algorithm iterates\n",
    "As the algorithm iterates, it is biasing the model to have a negative definite $\\mathbf{A}^S$ matrix. Once this is true, we can estimate the local Lyapunov stability radius $\\rho$, and see that as the algorithm promotes larger $-\\lambda_1$ (the max eigenvalue of $\\mathbf{A}^S$), the stability radius increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = sindy_opt.PWeigs_history_\n",
    "coef_history = sindy_opt.history_\n",
    "rhos = []\n",
    "for i in range(len(eigs)):\n",
    "    if eigs[i][-1] < 0:\n",
    "        # Q = np.tensordot(sindy_opt.PQ_, coef_history[i], axes=([4, 3], [1, 0]))\n",
    "        # Q_sum = Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])\n",
    "        rhos.append(-eigs[i][-1] / (2 * eps_Q))\n",
    "        # rhos.append(-eigs[i][-1] / np.max(np.abs(Q_sum)))\n",
    "plt.plot(rhos[1:])\n",
    "plt.grid(True)\n",
    "plt.ylabel('Stability radius')\n",
    "plt.xlabel('Algorithm iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for unbounded trajectories\n",
    "So we have used inequality constraints to promote locally Lyapunov stable models, and obtained an estimate of the stability radius. Let's verify that trajectories within this radius are bounded, but trajectories outside this radius can be unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, subplot_kw={'projection': '3d'}, figsize=(8, 8))\n",
    "t_sim = t\n",
    "for i in range(3):\n",
    "    a0 = (np.random.rand(r) - 0.5) * 20  #* rhos[-1]\n",
    "    x_traj = model.simulate(a0, t_sim)\n",
    "    plt.plot(x_traj[:, 0], x_traj[:, 1], x_traj[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have relaxed the hard constraint slightly and solved the trapping SINDy objective function with inequality constraints dictating the amount of deviation allowed from perfect skew-symmetry in the quadratic coefficients:\n",
    "$$ argmin_{\\mathbf{\\xi},\\mathbf m}\\|\\dot{\\mathbf a} - \\mathbf \\Theta(\\mathbf a) \\mathbf{\\xi}\\|^2 + \\gamma R(\\mathbf \\xi)  + \\eta^{-1} \\lambda_1(\\mathbf A)  \\quad s.t. \\quad -\\epsilon_Q \\leq Q_{ijk} + Q_{jik} + Q_{kji} \\leq \\epsilon_Q.$$ \n",
    "This allowed us to build locally Lyapunov stable models, and adjust the size of the local stability radius by varying $\\epsilon_Q$. However, two other loss terms that can be used as alternatives to increase the size of the stability radius while avoiding extra constraints:\n",
    "$$\\alpha^{-1}\\|Q_{ijk}\\|$$\n",
    "and\n",
    "$$\\beta^{-1}\\|Q_{ijk} + Q_{jki} + Q_{kij}\\|.$$\n",
    "We can combine all of these options into the following unconstrained optimization problem:\n",
    "$$argmin_{\\mathbf{\\xi},\\mathbf m}\\|\\dot{\\mathbf a} - \\mathbf \\Theta(\\mathbf a) \\mathbf{\\xi}\\|^2 + \\gamma R(\\mathbf \\xi)  + \\eta^{-1} \\lambda_1(\\mathbf A) + \\alpha^{-1}\\|Q_{ijk}\\| + \\beta^{-1}\\|Q_{ijk} + Q_{jki} + Q_{kij}\\|.$$\n",
    "We now solve this problem for $\\alpha \\gg \\beta$, $\\alpha \\ll \\beta$, and $\\alpha \\sim \\beta \\sim 1.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First case: $\\alpha \\gg 1$, $\\beta \\ll 1$, for which the model should just zero out all the quadratic nonlinear terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 5000\n",
    "eta = 1.0e2\n",
    "alpha = 1e-20\n",
    "beta = 1e20\n",
    "threshold = 0\n",
    "alpha_m = 1e-1 * eta\n",
    "\n",
    "# run trapping SINDy... no more constraints!\n",
    "sindy_opt = ps.TrappingSR3(\n",
    "    threshold=threshold, eta=eta,\n",
    "    alpha_m=alpha_m,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    max_iter=max_iter,\n",
    "    verbose=True,\n",
    ")\n",
    "model = ps.SINDy(\n",
    "    optimizer=sindy_opt,\n",
    "    feature_library=sindy_library,\n",
    ")\n",
    "model.fit(x_train, t=t)\n",
    "model.print()\n",
    "Xi = model.coefficients().T\n",
    "PL_tensor = sindy_opt.PL_\n",
    "PQ_tensor = sindy_opt.PQ_\n",
    "Lenergy = np.tensordot(PL_tensor, Xi, axes=([3, 2], [0, 1]))\n",
    "Qenergy = np.tensordot(PQ_tensor, Xi, axes=([4, 3], [0, 1]))\n",
    "mean_val = np.mean(x_test_pred, axis=0)\n",
    "mean_val = np.sqrt(np.sum(mean_val ** 2))\n",
    "check_stability(r, Xi, np.eye(r), sindy_opt, mean_val)\n",
    "Q = np.tensordot(sindy_opt.PQ_, Xi, axes=([4, 3], [0, 1]))\n",
    "print(np.max(np.abs((Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second case: $\\alpha \\ll 1$, $\\beta \\gg 1$, which should reproduce the energy-preserving nonlinear constraint to high accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter ... |y-Xw|^2 ... |Pw-A|^2/eta ... |w|_1 ... |Qijk|/a ... |Qijk+...|/b ...   Total:\n",
      "    0 ... 4.492e+02 ... 1.267e-03 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      " 2000 ... 4.492e+02 ... 7.650e-08 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      " 4000 ... 4.492e+02 ... 2.197e-08 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      " 6000 ... 4.492e+02 ... 1.226e-08 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      " 8000 ... 4.492e+02 ... 8.789e-09 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      "10000 ... 4.492e+02 ... 7.154e-09 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      "12000 ... 4.492e+02 ... 6.267e-09 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      "14000 ... 4.492e+02 ... 5.748e-09 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      "16000 ... 4.492e+02 ... 5.431e-09 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      "18000 ... 4.492e+02 ... 5.233e-09 ... 0.00e+00 ... 4.89e-11 ... 3.48e+01 ... 4.84e+02\n",
      "(x0)' = -10.047 x0 + 10.033 x1 + 0.002 x0x2 + -0.002 x1x2\n",
      "(x1)' = -0.063 1 + 27.740 x0 + -0.917 x1 + 0.007 x2 + -0.001 x0x1 + -0.993 x0x2 + -0.001 x1x2 + 0.001 x0x0\n",
      "(x2)' = 0.267 1 + 0.001 x0 + -0.002 x1 + -2.669 x2 + 0.984 x0x1 + 0.011 x0x0 + 0.004 x1x1\n",
      "optimal m:  [-1.22729453e+00 -5.56077419e-03  3.78704273e+01]\n",
      "As eigvals:  [-9.96702919 -2.69895619 -0.96803137]\n",
      "Estimate of trapping region size, Rm =  106.31550986068268\n",
      "Normalized trapping region size, Reff =  4.481135320047525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\CodeWork\\pysindy\\pysindy\\optimizers\\trapping_sr3.py:884: ConvergenceWarning: TrappingSR3._reduce did not converge after 20000 iters.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20000\n",
    "eta = 1.0e5\n",
    "alpha = 1e10\n",
    "beta = 1e-5\n",
    "threshold = 0\n",
    "alpha_m = 1e-1 * eta\n",
    "\n",
    "# run trapping SINDy... no more constraints!\n",
    "sindy_opt = ps.TrappingSR3(\n",
    "    threshold=threshold, eta=eta,\n",
    "    gamma=-1,\n",
    "    alpha_m=alpha_m,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    max_iter=max_iter,\n",
    "    verbose=True,\n",
    ")\n",
    "model = ps.SINDy(\n",
    "    optimizer=sindy_opt,\n",
    "    feature_library=sindy_library,\n",
    ")\n",
    "model.fit(x_train, t=t)\n",
    "model.print()\n",
    "Xi = model.coefficients().T\n",
    "PL_tensor = sindy_opt.PL_\n",
    "PQ_tensor = sindy_opt.PQ_\n",
    "Lenergy = np.tensordot(PL_tensor, Xi, axes=([3, 2], [0, 1]))\n",
    "Qenergy = np.tensordot(PQ_tensor, Xi, axes=([4, 3], [0, 1]))\n",
    "mean_val = np.mean(x_test_pred, axis=0)\n",
    "mean_val = np.sqrt(np.sum(mean_val ** 2))\n",
    "check_stability(r, Xi, np.eye(r), sindy_opt, mean_val)\n",
    "Q = np.tensordot(sindy_opt.PQ_, Xi, axes=([4, 3], [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot how the local stability radius changes as the algorithm iterates\n",
    "As the algorithm iterates, it is biasing the model to have a negative definite $\\mathbf{A}^S$ matrix. Once this is true, we can estimate the local Lyapunov stability radius $\\rho$, and see that as the algorithm promotes larger $-\\lambda_1$ (the max eigenvalue of $\\mathbf{A}^S$), the stability radius increases. \n",
    "\n",
    "#### Note that with the soft constraint we can get the stability radius arbitrarily large here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.91668296458744\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGwCAYAAACNeeBZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7uUlEQVR4nO3de1yUZf7/8feAHERFRAREUdQ8lWdNRLdsE8+tUa6ZuWnG2tY3s8Jco7XU2rIyTyXptqu2bZlmmZmZG6J2MEtDLQ9IZSqlgpoiGgoI1++Pfsw2chC8B5lxXs/Hw0fMdV/XPZ8PNzDv7rlnxmaMMQIAAMAl8aruAgAAANwZYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYUKO6C7gSFBUV6fDhw6pTp45sNlt1lwMAACrAGKPTp08rIiJCXl6Xfn6JMOUEhw8fVmRkZHWXAQAALsGPP/6oxo0bX/J6wpQT1KlTR9KvByMwMNBp+y0oKNBHH32kfv36ycfHx2n7dSWe0KPkGX16Qo+SZ/TpCT1KntEnPZYvJydHkZGR9sfxS0WYcoLip/YCAwOdHqYCAgIUGBh4Rf8SXOk9Sp7Rpyf0KHlGn57Qo+QZfdJjxVi9RIcL0AEAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYAFhCgAAwALCFAAAgAWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYIHbhamkpCRFRUXJ399f0dHR2rJlS7nzly9frjZt2sjf31/t27fXmjVrypx77733ymazac6cOU6uGgAAXKncKkwtW7ZMCQkJmjJlirZt26aOHTuqf//+Onr0aKnzP//8c40YMULx8fHavn274uLiFBcXp127dpWY++677+qLL75QREREVbcBAACuIG4VpmbNmqWxY8dqzJgxuvrqq7VgwQIFBARo0aJFpc6fO3euBgwYoIkTJ6pt27Z66qmn1KVLF82bN89h3qFDh/TAAw/ojTfekI+Pz+VoBQAAXCFqVHcBFZWfn6/U1FQlJibax7y8vBQbG6vNmzeXumbz5s1KSEhwGOvfv79Wrlxpv11UVKQ777xTEydO1DXXXFOhWvLy8pSXl2e/nZOTI0kqKChQQUFBRVu6qOJ9OXOfrsYTepQ8o09P6FHyjD49oUfJM/qkx4qttcptwtTx48dVWFiosLAwh/GwsDDt3bu31DWZmZmlzs/MzLTffu6551SjRg2NHz++wrVMnz5d06ZNKzH+0UcfKSAgoML7qajk5GSn79PVeEKPkmf06Qk9Sp7Rpyf0KHlGn/RYutzcXKfct9uEqaqQmpqquXPnatu2bbLZbBVel5iY6HDGKycnR5GRkerXr58CAwOdVl9BQYGSk5PVt2/fK/bpR0/oUfKMPj2hR8kz+vSEHiXP6JMey1f8zJJVbhOmQkJC5O3traysLIfxrKwshYeHl7omPDy83Pmffvqpjh49qiZNmti3FxYWasKECZozZ44OHDhQ6n79/Pzk5+dXYtzHx6dKflirar+uxBN6lDyjT0/oUfKMPj2hR8kz+qTHstc4g9tcgO7r66uuXbsqJSXFPlZUVKSUlBTFxMSUuiYmJsZhvvTracDi+Xfeeae++eYb7dixw/4vIiJCEydO1H//+9+qawYAAFwx3ObMlCQlJCRo9OjR6tatm7p37645c+bol19+0ZgxYyRJo0aNUqNGjTR9+nRJ0oMPPqjevXtr5syZGjx4sJYuXaqvvvpKr7zyiiSpfv36ql+/vsN9+Pj4KDw8XK1bt768zQEAALfkVmFq+PDhOnbsmJ544gllZmaqU6dOWrt2rf0i84yMDHl5/e9kW8+ePbVkyRJNnjxZjz32mFq2bKmVK1eqXbt21dUCAAC4wrhVmJKkcePGady4caVu27hxY4mxYcOGadiwYRXef1nXSQEAAJTGba6ZAgAAcEWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYAFhCgAAwALCFAAAgAWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYAFhCgAAwALCFAAAgAWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACtwtTSUlJioqKkr+/v6Kjo7Vly5Zy5y9fvlxt2rSRv7+/2rdvrzVr1ti3FRQUaNKkSWrfvr1q1aqliIgIjRo1SocPH67qNgAAwBXCrcLUsmXLlJCQoClTpmjbtm3q2LGj+vfvr6NHj5Y6//PPP9eIESMUHx+v7du3Ky4uTnFxcdq1a5ckKTc3V9u2bdPjjz+ubdu2acWKFUpPT9eQIUMuZ1sAAMCNuVWYmjVrlsaOHasxY8bo6quv1oIFCxQQEKBFixaVOn/u3LkaMGCAJk6cqLZt2+qpp55Sly5dNG/ePElS3bp1lZycrNtuu02tW7dWjx49NG/ePKWmpiojI+NytgYAANxUjeouoKLy8/OVmpqqxMRE+5iXl5diY2O1efPmUtds3rxZCQkJDmP9+/fXypUry7yfU6dOyWazKSgoqMw5eXl5ysvLs9/OycmR9OvThgUFBRXopmKK9+XMfboaT+hR8ow+PaFHyTP69IQeJc/okx4rttYqtwlTx48fV2FhocLCwhzGw8LCtHfv3lLXZGZmljo/MzOz1Pnnzp3TpEmTNGLECAUGBpZZy/Tp0zVt2rQS4x999JECAgIu1kqlJScnO32frsYTepQ8o09P6FHyjD49oUfJM/qkx9Ll5uY65b7dJkxVtYKCAt12220yxmj+/Pnlzk1MTHQ445WTk6PIyEj169ev3BB2KTUlJyerb9++8vHxcdp+XYkn9Ch5Rp+e0KPkGX16Qo+SZ/RJj+UrfmbJKrcJUyEhIfL29lZWVpbDeFZWlsLDw0tdEx4eXqH5xUHq4MGDWr9+/UUDkZ+fn/z8/EqM+/j4VMkPa1Xt15V4Qo+SZ/TpCT1KntGnJ/QoeUaf9Fj2GmdwmwvQfX191bVrV6WkpNjHioqKlJKSopiYmFLXxMTEOMyXfj0N+Nv5xUHqu+++07p161S/fv2qaQAAAFyR3ObMlCQlJCRo9OjR6tatm7p37645c+bol19+0ZgxYyRJo0aNUqNGjTR9+nRJ0oMPPqjevXtr5syZGjx4sJYuXaqvvvpKr7zyiqRfg9Qf//hHbdu2TatXr1ZhYaH9eqrg4GD5+vpWT6MAAMBtuFWYGj58uI4dO6YnnnhCmZmZ6tSpk9auXWu/yDwjI0NeXv872dazZ08tWbJEkydP1mOPPaaWLVtq5cqVateunSTp0KFDWrVqlSSpU6dODve1YcMG3XDDDZelLwAA4L7cKkxJ0rhx4zRu3LhSt23cuLHE2LBhwzRs2LBS50dFRckY48zyAACAh3Gba6YAAABcEWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYAFhCgAAwIJKh6m1a9fqs88+s99OSkpSp06ddMcdd+jkyZNOLQ4AAMDVVTpMTZw4UTk5OZKknTt3asKECRo0aJD279+vhIQEpxcIAADgyir9Qcf79+/X1VdfLUl65513dNNNN+mZZ57Rtm3bNGjQIKcXCAAA4MoqfWbK19dXubm5kqR169apX79+kqTg4GD7GSsAAABPUekzU7/73e+UkJCgXr16acuWLVq2bJkk6dtvv1Xjxo2dXiAAAIArq/SZqXnz5qlGjRp6++23NX/+fDVq1EiS9OGHH2rAgAFOLxAAAMCVVfrMVJMmTbR69eoS47Nnz3ZKQQAAAO6k0mEqIyOj3O1NmjS55GIAAADcTaXDVFRUlGw2W5nbCwsLLRUEAADgTiodprZv3+5wu6CgQNu3b9esWbP09NNPO60wAAAAd1DpMNWxY8cSY926dVNERIRmzJihW2+91SmFAQAAuAOnfTZf69attXXrVmftDgAAwC1U+szUhW/MaYzRkSNHNHXqVLVs2dJphQEAALiDSoepoKCgEhegG2MUGRmppUuXOq0wAAAAd1DpMLVhwwaH215eXmrQoIGuuuoq1ahR6d0BAAC4tUqnn969e1dFHQAAAG6pQmFq1apVGjhwoHx8fLRq1apy5w4ZMsQphQEAALiDCoWpuLg4ZWZmKjQ0VHFxcWXOs9lsvGknAADwKBUKU0VFRaV+DQAA4Omc9j5TAAAAnqhCZ6ZefPHFCu9w/Pjxl1wMAACAu6lQmJo9e7bD7WPHjik3N1dBQUGSpOzsbAUEBCg0NJQwBQAAPEqFnubbv3+//d/TTz+tTp06KS0tTSdOnNCJEyeUlpamLl266KmnnqrqegEAAFxKpa+Zevzxx/XSSy+pdevW9rHWrVtr9uzZmjx5slOLAwAAcHWVDlNHjhzR+fPnS4wXFhYqKyvLKUUBAAC4i0qHqT59+ugvf/mLtm3bZh9LTU3Vfffdp9jYWKcWBwAA4OoqHaYWLVqk8PBwdevWTX5+fvLz81P37t0VFhamf/3rX1VRIwAAgMuq9GfzNWjQQGvWrNG3336rvXv3SpLatGmjVq1aOb04AAAAV1fpMFWsVatWBCgAAODxLilM/fTTT1q1apUyMjKUn5/vsG3WrFlOKQwAAMAdVDpMpaSkaMiQIWrevLn27t2rdu3a6cCBAzLGqEuXLlVRIwAAgMuq9AXoiYmJeuSRR7Rz5075+/vrnXfe0Y8//qjevXtr2LBhVVEjAACAy6p0mEpLS9OoUaMkSTVq1NDZs2dVu3ZtPfnkk3ruueecXiAAAIArq3SYqlWrlv06qYYNG2rfvn32bcePH3deZQAAAG6g0tdM9ejRQ5999pnatm2rQYMGacKECdq5c6dWrFihHj16VEWNAAAALqvSYWrWrFk6c+aMJGnatGk6c+aMli1bppYtW/JKPgAA4HEqFaYKCwv1008/qUOHDpJ+fcpvwYIFVVIYAACAO6jUNVPe3t7q16+fTp48WVX1AAAAuJVKX4Derl07/fDDD1VRCwAAgNupdJj6+9//rkceeUSrV6/WkSNHlJOT4/APAADAk1T6AvRBgwZJkoYMGSKbzWYfN8bIZrOpsLDQedUBAAC4uEqHqQ0bNlRFHQAAAG6p0mGqd+/eVVEHAACAW6r0NVMAAAD4H8IUAACABYQpAAAAC9wuTCUlJSkqKkr+/v6Kjo7Wli1byp2/fPlytWnTRv7+/mrfvr3WrFnjsN0YoyeeeEINGzZUzZo1FRsbq++++64qWwAAAFeQSoepKVOm6ODBg1VRy0UtW7ZMCQkJmjJlirZt26aOHTuqf//+Onr0aKnzP//8c40YMULx8fHavn274uLiFBcXp127dtnnPP/883rxxRe1YMECffnll6pVq5b69++vc+fOXa62AACAG6v0q/nee+89Pf300+rdu7fi4+M1dOhQ+fn5VUVtJcyaNUtjx47VmDFjJEkLFizQBx98oEWLFunRRx8tMX/u3LkaMGCAJk6cKEl66qmnlJycrHnz5mnBggUyxmjOnDmaPHmybr75ZknSa6+9prCwMK1cuVK33377ZemrLIeyz+pE3q//rVGjoFprqSrnz5+/4nuUPKNPT+hR8ow+PaFHyTP6vJJ6bBRU0+H9LV2JzRhjKrto+/btWrx4sd58802dP39et99+u+6++25de+21VVGjJCk/P18BAQF6++23FRcXZx8fPXq0srOz9d5775VY06RJEyUkJOihhx6yj02ZMkUrV67U119/rR9++EEtWrTQ9u3b1alTJ/uc3r17q1OnTpo7d26pteTl5SkvL89+OycnR5GRkTp+/LgCAwMt91rsmqnrlF9Y5LT9AQDgrnZPiZVvjZJPqBUUFCg5OVl9+/aVj49PpfaZk5OjkJAQnTp1ytLjd6XPTElS586d1blzZ82cOVPvv/++Fi9erF69eqlNmzaKj4/XXXfdpbp1615yUaU5fvy4CgsLFRYW5jAeFhamvXv3lromMzOz1PmZmZn27cVjZc0pzfTp0zVt2rQS4x999JECAgIu3kwFectbPq4ZwgEAuKzWrl2rUrKUXXJycqX3mZuba6Gi/7mkMFXMGKOCggLl5+fLGKN69epp3rx5evzxx/XPf/5Tw4cPd0qRriYxMVEJCQn228Vnpvr16+fUM1N9+1562nYXVv6Pwp14Qp+e0KPkGX16Qo+SZ/RJj+Vz1mcKX1KYSk1NtT/N5+fnp1GjRikpKUlXXXWVJOmll17S+PHjnRqmQkJC5O3traysLIfxrKwshYeHl7omPDy83PnF/83KylLDhg0d5vz2ab8L+fn5lXqdmI+PT5X8sFbVfl2JJ/QoeUafntCj5Bl9ekKPkmf0SY9lr3GGSr+ar3379urRo4f279+vhQsX6scff9Szzz5rD1KSNGLECB07dswpBRbz9fVV165dlZKSYh8rKipSSkqKYmJiSl0TExPjMF/69TRg8fxmzZopPDzcYU5OTo6+/PLLMvcJAADwW5U+M3Xbbbfp7rvvVqNGjcqcExISoqIi5184nZCQoNGjR6tbt27q3r275syZo19++cX+6r5Ro0apUaNGmj59uiTpwQcfVO/evTVz5kwNHjxYS5cu1VdffaVXXnlFkmSz2fTQQw/p73//u1q2bKlmzZrp8ccfV0REhMNF7gAAAGWpdJgqvjbqQmfPntWMGTP0xBNPOKWw0gwfPlzHjh3TE088oczMTHXq1Elr1661X0CekZEhL6//nWzr2bOnlixZosmTJ+uxxx5Ty5YttXLlSrVr184+569//at++eUX3XPPPcrOztbvfvc7rV27Vv7+/lXWBwAAuHJU+mm+adOm6cyZMyXGc3NzS32Fm7ONGzdOBw8eVF5enr788ktFR0fbt23cuFGvvvqqw/xhw4YpPT1deXl52rVrlwYNGuSw3Waz6cknn1RmZqbOnTundevWqVWrVlXeBwAAuDJUOkwZY0p906yvv/5awcHBTikKAADAXVT4ab569erJZrPJZrOpVatWDoGqsLBQZ86c0b333lslRQIAALiqCoepOXPmyBiju+++W9OmTXN4U05fX19FRUXxCjgAAOBxKhymRo8eLenXtxPo2bPnFf9+FQAAABVRoTCVk5Njf2fvzp076+zZszp79mypc535DuAAAACurkJhql69ejpy5IhCQ0MVFBRU6gXoxRemFxYWOr1IAAAAV1WhMLV+/Xr7K/U2bNhQpQUBAAC4kwqFqd69e5f6NQAAgKerUJj65ptvKrzDDh06XHIxAAAA7qZCYapTp06y2WwyxpQ7j2umAACAp6lQmNq/f39V1wEAAOCWKhSmmjZtWtV1AAAAuKUKhalVq1Zp4MCB8vHx0apVq8qdO2TIEKcUBgAA4A4qFKbi4uKUmZmp0NBQxcXFlTmPa6YAAICnqVCYKioqKvVrAAAAT+dV3QUAAAC4s0sKUykpKbrpppvUokULtWjRQjfddJPWrVvn7NoAAABcXqXD1Msvv6wBAwaoTp06evDBB/Xggw8qMDBQgwYNUlJSUlXUCAAA4LIqdM3Ubz3zzDOaPXu2xo0bZx8bP368evXqpWeeeUb333+/UwsEAABwZZU+M5Wdna0BAwaUGO/Xr59OnTrllKIAAADcRaXD1JAhQ/Tuu++WGH/vvfd00003OaUoAAAAd1Ghp/lefPFF+9dXX321nn76aW3cuFExMTGSpC+++EKbNm3ShAkTqqZKAAAAF1WhMDV79myH2/Xq1dOePXu0Z88e+1hQUJAWLVqkyZMnO7dCAAAAF8YHHQMAAFjAm3YCAABYUOm3RpCkn376SatWrVJGRoby8/Mdts2aNcsphQEAALiDSoeplJQUDRkyRM2bN9fevXvVrl07HThwQMYYdenSpSpqBAAAcFmVfpovMTFRjzzyiHbu3Cl/f3+98847+vHHH9W7d28NGzasKmoEAABwWZUOU2lpaRo1apQkqUaNGjp79qxq166tJ598Us8995zTCwQAAHBllQ5TtWrVsl8n1bBhQ+3bt8++7fjx486rDAAAwA1U+pqpHj166LPPPlPbtm01aNAgTZgwQTt37tSKFSvUo0ePqqgRAADAZVU6TM2aNUtnzpyRJE2bNk1nzpzRsmXL1LJlS17JBwAAPE6lw1Tz5s3tX9eqVUsLFixwakEAAADupNLXTDVv3lw///xzifHs7GyHoAUAAOAJKh2mDhw4oMLCwhLjeXl5OnTokFOKAgAAcBcVfppv1apV9q//+9//qm7duvbbhYWFSklJUVRUlFOLAwAAcHUVDlNxcXGSJJvNptGjRzts8/HxUVRUlGbOnOnU4gAAAFxdhcNUUVGRJKlZs2baunWrQkJCqqwoAAAAd1HpV/Pt37+/KuoAAABwSxW+AH3z5s1avXq1w9hrr72mZs2aKTQ0VPfcc4/y8vKcXiAAAIArq3CYevLJJ7V792777Z07dyo+Pl6xsbF69NFH9f7772v69OlVUiQAAICrqnCY2rFjh/r06WO/vXTpUkVHR+uf//ynEhIS9OKLL+qtt96qkiIBAABcVYXD1MmTJxUWFma//fHHH2vgwIH229dee61+/PFH51YHAADg4iocpsLCwuwXn+fn52vbtm0OH2x8+vRp+fj4OL9CAAAAF1bhMDVo0CA9+uij+vTTT5WYmKiAgABdd9119u3ffPONWrRoUSVFAgAAuKoKvzXCU089pVtvvVW9e/dW7dq19e9//1u+vr727YsWLVK/fv2qpEgAAABXVeEwFRISok8++USnTp1S7dq15e3t7bB9+fLlql27ttMLBAAAcGWVftPO334m328FBwdbLgYAAMDdVPiaKQAAAJREmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABY4DZh6sSJExo5cqQCAwMVFBSk+Ph4nTlzptw1586d0/3336/69eurdu3aGjp0qLKysuzbv/76a40YMUKRkZGqWbOm2rZtq7lz51Z1KwAA4AriNmFq5MiR2r17t5KTk7V69Wp98sknuueee8pd8/DDD+v999/X8uXL9fHHH+vw4cO69dZb7dtTU1MVGhqq119/Xbt379bf/vY3JSYmat68eVXdDgAAuEJU+rP5qkNaWprWrl2rrVu3qlu3bpKkl156SYMGDdILL7ygiIiIEmtOnTqlhQsXasmSJbrxxhslSYsXL1bbtm31xRdfqEePHrr77rsd1jRv3lybN2/WihUrNG7cuDLrycvLU15env12Tk6OJKmgoEAFBQWW+y1WvC9n7tPVeEKPkmf06Qk9Sp7Rpyf0KHlGn/RYsbVW2Ywxxil7qkKLFi3ShAkTdPLkSfvY+fPn5e/vr+XLl+uWW24psWb9+vXq06ePTp48qaCgIPt406ZN9dBDD+nhhx8u9b7+9Kc/6dy5c3r77bfLrGfq1KmaNm1aifElS5YoICCgEp0BAIDqkpubqzvuuEOnTp1SYGDgJe/HLc5MZWZmKjQ01GGsRo0aCg4OVmZmZplrfH19HYKUJIWFhZW55vPPP9eyZcv0wQcflFtPYmKiEhIS7LdzcnIUGRmpfv36WToYFyooKFBycrL69u0rHx8fp+3XlXhCj5Jn9OkJPUqe0acn9Ch5Rp/0WL7iZ5asqtYw9eijj+q5554rd05aWtplqWXXrl26+eabNWXKFPXr16/cuX5+fvLz8ysx7uPjUyU/rFW1X1fiCT1KntGnJ/QoeUafntCj5Bl90mPZa5yhWsPUhAkTdNddd5U7p3nz5goPD9fRo0cdxs+fP68TJ04oPDy81HXh4eHKz89Xdna2w9mprKysEmv27NmjPn366J577tHkyZMvqRcAAOCZqjVMNWjQQA0aNLjovJiYGGVnZys1NVVdu3aV9Os1UUVFRYqOji51TdeuXeXj46OUlBQNHTpUkpSenq6MjAzFxMTY5+3evVs33nijRo8eraefftoJXQEAAE/iFm+N0LZtWw0YMEBjx47Vli1btGnTJo0bN0633367/ZV8hw4dUps2bbRlyxZJUt26dRUfH6+EhARt2LBBqampGjNmjGJiYtSjRw9Jvz619/vf/179+vVTQkKCMjMzlZmZqWPHjlVbrwAAwL24xQXokvTGG29o3Lhx6tOnj7y8vDR06FC9+OKL9u0FBQVKT09Xbm6ufWz27Nn2uXl5eerfv79efvll+/a3335bx44d0+uvv67XX3/dPt60aVMdOHDgsvQFAADcm9uEqeDgYC1ZsqTM7VFRUbrwXR78/f2VlJSkpKSkUtdMnTpVU6dOdWaZAADAw7jF03wAAACuijAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYAFhCgAAwALCFAAAgAWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYAFhCgAAwALCFAAAgAWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWOA2YerEiRMaOXKkAgMDFRQUpPj4eJ05c6bcNefOndP999+v+vXrq3bt2ho6dKiysrJKnfvzzz+rcePGstlsys7OroIOAADAlchtwtTIkSO1e/duJScna/Xq1frkk090zz33lLvm4Ycf1vvvv6/ly5fr448/1uHDh3XrrbeWOjc+Pl4dOnSoitIBAMAVrEZ1F1ARaWlpWrt2rbZu3apu3bpJkl566SUNGjRIL7zwgiIiIkqsOXXqlBYuXKglS5boxhtvlCQtXrxYbdu21RdffKEePXrY586fP1/Z2dl64okn9OGHH160nry8POXl5dlv5+TkSJIKCgpUUFBgqdffKt6XM/fpajyhR8kz+vSEHiXP6NMTepQ8o096rNhaq2zGGOOUPVWhRYsWacKECTp58qR97Pz58/L399fy5ct1yy23lFizfv169enTRydPnlRQUJB9vGnTpnrooYf08MMPS5L27NmjPn366Msvv9QPP/yg3//+9yXWXGjq1KmaNm1aifElS5YoICDg0hsFAACXTW5uru644w6dOnVKgYGBl7wftzgzlZmZqdDQUIexGjVqKDg4WJmZmWWu8fX1LRGKwsLC7Gvy8vI0YsQIzZgxQ02aNNEPP/xQoXoSExOVkJBgv52Tk6PIyEj169fP0sG4UEFBgZKTk9W3b1/5+Pg4bb+uxBN6lDyjT0/oUfKMPj2hR8kz+qTH8hU/s2RVtYapRx99VM8991y5c9LS0qrs/hMTE9W2bVv96U9/qtQ6Pz8/+fn5lRj38fGpkh/WqtqvK/GEHiXP6NMTepQ8o09P6FHyjD7psew1zlCtYWrChAm66667yp3TvHlzhYeH6+jRow7j58+f14kTJxQeHl7quvDwcOXn5ys7O9vh7FRWVpZ9zfr167Vz5069/fbbkqTiZzxDQkL0t7/9rdSn8gAAAH6rWsNUgwYN1KBBg4vOi4mJUXZ2tlJTU9W1a1dJvwahoqIiRUdHl7qma9eu8vHxUUpKioYOHSpJSk9PV0ZGhmJiYiRJ77zzjs6ePWtfs3XrVt1999369NNP1aJFC6vtAQAAD+AW10y1bdtWAwYM0NixY7VgwQIVFBRo3Lhxuv322+2v5Dt06JD69Omj1157Td27d1fdunUVHx+vhIQEBQcHKzAwUA888IBiYmLsr+S7MDAdP37cfn/lXYAOAABQzC3ClCS98cYbGjdunPr06SMvLy8NHTpUL774on17QUGB0tPTlZubax+bPXu2fW5eXp769++vl19+uTrKBwAAVyi3CVPBwcFasmRJmdujoqJ04bs8+Pv7KykpSUlJSRW6jxtuuKHEPgAAAMrjNu+ADgAA4IoIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFhCmAAAALCBMAQAAWECYAgAAsIAwBQAAYAFhCgAAwALCFAAAgAWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYQoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKAADAAsIUAACABYQpAAAACwhTAAAAFtSo7gKuBMYYSVJOTo5T91tQUKDc3Fzl5OTIx8fHqft2FZ7Qo+QZfXpCj5Jn9OkJPUqe0Sc9lq/4cbv4cfxSEaac4PTp05KkyMjIaq4EAABU1unTp1W3bt1LXm8zVuMYVFRUpMOHD6tOnTqy2WxO229OTo4iIyP1448/KjAw0Gn7dSWe0KPkGX16Qo+SZ/TpCT1KntEnPZbPGKPTp08rIiJCXl6XfuUTZ6acwMvLS40bN66y/QcGBl6xvwTFPKFHyTP69IQeJc/o0xN6lDyjT3osm5UzUsW4AB0AAMACwhQAAIAFhCkX5ufnpylTpsjPz6+6S6kyntCj5Bl9ekKPkmf06Qk9Sp7RJz1eHlyADgAAYAFnpgAAACwgTAEAAFhAmAIAALCAMAUAAGABYcqFJSUlKSoqSv7+/oqOjtaWLVuqu6RSTZ8+Xddee63q1Kmj0NBQxcXFKT093WHODTfcIJvN5vDv3nvvdZiTkZGhwYMHKyAgQKGhoZo4caLOnz/vMGfjxo3q0qWL/Pz8dNVVV+nVV1+t6vYkSVOnTi1Rf5s2bezbz507p/vvv1/169dX7dq1NXToUGVlZTnsw5X7KxYVFVWiT5vNpvvvv1+Sex7HTz75RH/4wx8UEREhm82mlStXOmw3xuiJJ55Qw4YNVbNmTcXGxuq7775zmHPixAmNHDlSgYGBCgoKUnx8vM6cOeMw55tvvtF1110nf39/RUZG6vnnny9Ry/Lly9WmTRv5+/urffv2WrNmzWXps6CgQJMmTVL79u1Vq1YtRUREaNSoUTp8+LDDPko7/s8++6zL9HmxY3nXXXeVqH/AgAEOc9z9WEoq9XfUZrNpxowZ9jmufCwr8phxOf+mOuWx1sAlLV261Pj6+ppFixaZ3bt3m7Fjx5qgoCCTlZVV3aWV0L9/f7N48WKza9cus2PHDjNo0CDTpEkTc+bMGfuc3r17m7Fjx5ojR47Y/506dcq+/fz586Zdu3YmNjbWbN++3axZs8aEhISYxMRE+5wffvjBBAQEmISEBLNnzx7z0ksvGW9vb7N27doq73HKlCnmmmuucaj/2LFj9u333nuviYyMNCkpKearr74yPXr0MD179nSb/oodPXrUocfk5GQjyWzYsMEY457Hcc2aNeZvf/ubWbFihZFk3n33XYftzz77rKlbt65ZuXKl+frrr82QIUNMs2bNzNmzZ+1zBgwYYDp27Gi++OIL8+mnn5qrrrrKjBgxwr791KlTJiwszIwcOdLs2rXLvPnmm6ZmzZrmH//4h33Opk2bjLe3t3n++efNnj17zOTJk42Pj4/ZuXNnlfeZnZ1tYmNjzbJly8zevXvN5s2bTffu3U3Xrl0d9tG0aVPz5JNPOhzf3/4eV3efFzuWo0ePNgMGDHCo/8SJEw5z3P1YGmMc+jty5IhZtGiRsdlsZt++ffY5rnwsK/KYcbn+pjrrsZYw5aK6d+9u7r//fvvtwsJCExERYaZPn16NVVXM0aNHjSTz8ccf28d69+5tHnzwwTLXrFmzxnh5eZnMzEz72Pz5801gYKDJy8szxhjz17/+1VxzzTUO64YPH2769+/v3AZKMWXKFNOxY8dSt2VnZxsfHx+zfPly+1haWpqRZDZv3myMcf3+yvLggw+aFi1amKKiImOM+x/HCx+YioqKTHh4uJkxY4Z9LDs72/j5+Zk333zTGGPMnj17jCSzdetW+5wPP/zQ2Gw2c+jQIWOMMS+//LKpV6+evUdjjJk0aZJp3bq1/fZtt91mBg8e7FBPdHS0+ctf/uLUHo0p2WdptmzZYiSZgwcP2seaNm1qZs+eXeYaV+qzrDB18803l7nmSj2WN998s7nxxhsdxtzpWF74mHE5/6Y667GWp/lcUH5+vlJTUxUbG2sf8/LyUmxsrDZv3lyNlVXMqVOnJEnBwcEO42+88YZCQkLUrl07JSYmKjc3175t8+bNat++vcLCwuxj/fv3V05Ojnbv3m2f89vvSfGcy/U9+e677xQREaHmzZtr5MiRysjIkCSlpqaqoKDAobY2bdqoSZMm9trcob8L5efn6/XXX9fdd9/t8AHe7n4cf2v//v3KzMx0qKdu3bqKjo52OHZBQUHq1q2bfU5sbKy8vLz05Zdf2udcf/318vX1tc/p37+/0tPTdfLkSfscV+lb+vX31GazKSgoyGH82WefVf369dW5c2fNmDHD4WkTd+hz48aNCg0NVevWrXXffffp559/dqj/SjuWWVlZ+uCDDxQfH19im7scywsfMy7X31RnPtbyQccu6Pjx4yosLHT4IZGksLAw7d27t5qqqpiioiI99NBD6tWrl9q1a2cfv+OOO9S0aVNFRETom2++0aRJk5Senq4VK1ZIkjIzM0vtt3hbeXNycnJ09uxZ1axZs8r6io6O1quvvqrWrVvryJEjmjZtmq677jrt2rVLmZmZ8vX1LfGgFBYWdtHai7eVN+dy9FealStXKjs7W3fddZd9zN2P44WKayqtnt/WGxoa6rC9Ro0aCg4OdpjTrFmzEvso3lavXr0y+y7ex+V07tw5TZo0SSNGjHD4YNjx48erS5cuCg4O1ueff67ExEQdOXJEs2bNkuT6fQ4YMEC33nqrmjVrpn379umxxx7TwIEDtXnzZnl7e1+Rx/Lf//636tSpo1tvvdVh3F2OZWmPGZfrb+rJkyed9lhLmIJT3X///dq1a5c+++wzh/F77rnH/nX79u3VsGFD9enTR/v27VOLFi0ud5mVNnDgQPvXHTp0UHR0tJo2baq33nrrsoecy2XhwoUaOHCgIiIi7GPufhzx68Xot912m4wxmj9/vsO2hIQE+9cdOnSQr6+v/vKXv2j69Olu8XEkt99+u/3r9u3bq0OHDmrRooU2btyoPn36VGNlVWfRokUaOXKk/P39Hcbd5ViW9ZjhbniazwWFhITI29u7xCsXsrKyFB4eXk1VXdy4ceO0evVqbdiwQY0bNy53bnR0tCTp+++/lySFh4eX2m/xtvLmBAYGXvZAExQUpFatWun7779XeHi48vPzlZ2dXaK2i9VevK28OdXR38GDB7Vu3Tr9+c9/Lneeux/H4prK+10LDw/X0aNHHbafP39eJ06ccMrxvZy/08VB6uDBg0pOTnY4K1Wa6OhonT9/XgcOHJDkPn0Wa968uUJCQhx+Pq+UYylJn376qdLT0y/6eyq55rEs6zHjcv1NdeZjLWHKBfn6+qpr165KSUmxjxUVFSklJUUxMTHVWFnpjDEaN26c3n33Xa1fv77EqePS7NixQ5LUsGFDSVJMTIx27tzp8Ieu+I/91VdfbZ/z2+9J8Zzq+J6cOXNG+/btU8OGDdW1a1f5+Pg41Jaenq6MjAx7be7W3+LFixUaGqrBgweXO8/dj2OzZs0UHh7uUE9OTo6+/PJLh2OXnZ2t1NRU+5z169erqKjIHiZjYmL0ySefqKCgwD4nOTlZrVu3Vr169exzqrPv4iD13Xffad26dapfv/5F1+zYsUNeXl72p8bcoc/f+umnn/Tzzz87/HxeCcey2MKFC9W1a1d17NjxonNd6Vhe7DHjcv1NdepjbaUuV8dls3TpUuPn52deffVVs2fPHnPPPfeYoKAgh1cuuIr77rvP1K1b12zcuNHhZbi5ubnGGGO+//578+STT5qvvvrK7N+/37z33numefPm5vrrr7fvo/hlrv369TM7duwwa9euNQ0aNCj1Za4TJ040aWlpJikp6bK9dcCECRPMxo0bzf79+82mTZtMbGysCQkJMUePHjXG/Poy3iZNmpj169ebr776ysTExJiYmBi36e+3CgsLTZMmTcykSZMcxt31OJ4+fdps377dbN++3Ugys2bNMtu3b7e/iu3ZZ581QUFB5r333jPffPONufnmm0t9a4TOnTubL7/80nz22WemZcuWDi+nz87ONmFhYebOO+80u3btMkuXLjUBAQElXmZeo0YN88ILL5i0tDQzZcoUp76cvrw+8/PzzZAhQ0zjxo3Njh07HH5Pi1/59Pnnn5vZs2ebHTt2mH379pnXX3/dNGjQwIwaNcpl+iyvx9OnT5tHHnnEbN682ezfv9+sW7fOdOnSxbRs2dKcO3fOvg93P5bFTp06ZQICAsz8+fNLrHf1Y3mxxwxjLt/fVGc91hKmXNhLL71kmjRpYnx9fU337t3NF198Ud0llUpSqf8WL15sjDEmIyPDXH/99SY4ONj4+fmZq666ykycONHh/YmMMebAgQNm4MCBpmbNmiYkJMRMmDDBFBQUOMzZsGGD6dSpk/H19TXNmze330dVGz58uGnYsKHx9fU1jRo1MsOHDzfff/+9ffvZs2fN//3f/5l69eqZgIAAc8stt5gjR4447MOV+/ut//73v0aSSU9Pdxh31+O4YcOGUn8+R48ebYz59e0RHn/8cRMWFmb8/PxMnz59SvT+888/mxEjRpjatWubwMBAM2bMGHP69GmHOV9//bX53e9+Z/z8/EyjRo3Ms88+W6KWt956y7Rq1cr4+vqaa665xnzwwQeXpc/9+/eX+Xta/B5iqampJjo62tStW9f4+/ubtm3bmmeeecYhiFR3n+X1mJuba/r162caNGhgfHx8TNOmTc3YsWNLPCi6+7Es9o9//MPUrFnTZGdnl1jv6sfyYo8Zxlzev6nOeKy1/f/GAAAAcAm4ZgoAAMACwhQAAIAFhCkAAAALCFMAAAAWEKYAAAAsIEwBAABYQJgCAACwgDAFAABgAWEKgGUbN26UzWYr8cGk1XlfUVFRmjNnjsvUc7lNnTpVnTp1qu4yAI9AmAJQIZs3b5a3t/dFP/y4qvXs2VNHjhxR3bp1JUmvvvqqgoKCPLoem82mlStXOow98sgjJT7kFUDVIEwBqJCFCxfqgQce0CeffKLDhw9XSw0FBQXy9fVVeHi4bDZbtdRwoaqqp7CwUEVFRZe8vnbt2qpfv74TKwJQFsIUgIs6c+aMli1bpvvuu0+DBw/Wq6++etE1//znPxUZGamAgADdcsstmjVrVokzNvPnz1eLFi3k6+ur1q1b6z//+Y/DdpvNpvnz52vIkCGqVauWnn76aYen1TZu3KgxY8bo1KlTstlsstlsmjp1qn19bm6u7r77btWpU0dNmjTRK6+8Yt924MAB2Ww2vfXWW7ruuutUs2ZNXXvttfr222+1detWdevWTbVr19bAgQN17NixMvusaD15eXl65JFH1KhRI9WqVUvR0dHauHGjfT/FZ7RWrVqlq6++Wn5+fsrIyNDWrVvVt29fhYSEqG7duurdu7e2bdtmXxcVFSVJuuWWW2Sz2ey3L3yar6ioSE8++aQaN24sPz8/derUSWvXri3x/VixYoV+//vfKyAgQB07dtTmzZvLOcoAJEmV/mhkAB5n4cKFplu3bsYYY95//33TokULU1RUZN9e/Cn3J0+eNMYY89lnnxkvLy8zY8YMk56ebpKSkkxwcLCpW7eufc2KFSuMj4+PSUpKMunp6WbmzJnG29vbrF+/3j5HkgkNDTWLFi0y+/btMwcPHnS4r7y8PDNnzhwTGBhojhw5Yo4cOWJOnz5tjDGmadOmJjg42CQlJZnvvvvOTJ8+3Xh5eZm9e/caY4zZv3+/kWTatGlj1q5da/bs2WN69Ohhunbtam644Qbz2WefmW3btpmrrrrK3HvvvWV+bypaz5///GfTs2dP88knn5jvv//ezJgxw/j5+Zlvv/3WGGPM4sWLjY+Pj+nZs6fZtGmT2bt3r/nll19MSkqK+c9//mPS0tLMnj17THx8vAkLCzM5OTnGGGOOHj1qJJnFixebI0eOmKNHjxpjjJkyZYrp2LGjvc5Zs2aZwMBA8+abb5q9e/eav/71r8bHx8d+/7/9fqxevdqkp6ebP/7xj6Zp06amoKCg0j8zgCchTAG4qJ49e5o5c+YYY4wpKCgwISEhZsOGDfbtF4ap4cOHm8GDBzvsY+TIkQ5hqmfPnmbs2LEOc4YNG2YGDRpkvy3JPPTQQw5zLryvxYsXO+y3WNOmTc2f/vQn++2ioiITGhpq5s+fb4z5X3j417/+ZZ/z5ptvGkkmJSXFPjZ9+nTTunXrMr4zFavn4MGDxtvb2xw6dMhhvE+fPiYxMdG+TpLZsWNHmfdljDGFhYWmTp065v3337ePSTLvvvuuw7wLw1RERIR5+umnHeZce+215v/+7/+MMaV/P3bv3m0kmbS0tHJrAjwdT/MBKFd6erq2bNmiESNGSJJq1Kih4cOHa+HCheWu6d69u8PYhbfT0tLUq1cvh7FevXopLS3NYaxbt26XXHuHDh3sX9tsNoWHh+vo0aNlzgkLC5MktW/f3mHswjWVtXPnThUWFqpVq1aqXbu2/d/HH3+sffv22ef5+vo61CNJWVlZGjt2rFq2bKm6desqMDBQZ86cUUZGRoXvPycnR4cPH67Q9/u399+wYUNJstw/cKWrUd0FAHBtCxcu1Pnz5xUREWEfM8bIz89P8+bNs7+KrarUqlXrktf6+Pg43LbZbCUu6v7tnOKLyC8cs3IhuPTrNWfe3t5KTU2Vt7e3w7batWvbv65Zs2aJC9lHjx6tn3/+WXPnzlXTpk3l5+enmJgY5efnW6qpLKV9P6z2D1zpODMFoEznz5/Xa6+9ppkzZ2rHjh32f19//bUiIiL05ptvlrqudevW2rp1q8PYhbfbtm2rTZs2OYxt2rRJV199daVq9PX1VWFhYaXWVKXS6uncubMKCwt19OhRXXXVVQ7/wsPDy93fpk2bNH78eA0aNEjXXHON/Pz8dPz4cYc5Pj4+5X4PAgMDFRER4ZTvN4CSODMFoEyrV6/WyZMnFR8fX+IM1NChQ7Vw4ULde++9JdY98MADuv766zVr1iz94Q9/0Pr16/Xhhx86nHWZOHGibrvtNnXu3FmxsbF6//33tWLFCq1bt65SNUZFRenMmTNKSUlRx44dFRAQoICAgEtr2AlKq6dVq1YaOXKkRo0apZkzZ6pz5846duyYUlJS1KFDh3Lfu6tly5b6z3/+o27duiknJ0cTJ05UzZo1S9xnSkqKevXqJT8/P9WrV6/EfiZOnKgpU6aoRYsW6tSpkxYvXqwdO3bojTfecPr3APA0nJkCUKaFCxcqNja21Kfyhg4dqq+++krffPNNiW29evXSggULNGvWLHXs2FFr167Vww8/LH9/f/ucuLg4zZ07Vy+88IKuueYa/eMf/9DixYt1ww03VKrGnj176t5779Xw4cPVoEEDPf/885Xu05nKqmfx4sUaNWqUJkyYoNatWysuLk5bt25VkyZNyt3fwoULdfLkSXXp0kV33nmnxo8fr9DQUIc5M2fOVHJysiIjI9W5c+dS9zN+/HglJCRowoQJat++vdauXatVq1apZcuWzmkc8GA2Y4yp7iIAXPnGjh2rvXv36tNPP63uUgDAqXiaD0CVeOGFF9S3b1/VqlVLH374of7973/r5Zdfru6yAMDpODMFoErcdttt2rhxo06fPq3mzZvrgQceKPX6KgBwd4QpAAAAC7gAHQAAwALCFAAAgAWEKQAAAAsIUwAAABYQpgAAACwgTAEAAFhAmAIAALCAMAUAAGDB/wN4d3DPychTogAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01311855595121144\n",
      "[[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "[ 0.0003308  -0.0632004   0.26667605]\n",
      "[[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "[ 0.0003308  -0.0632004   0.26667605]\n",
      "[[-1.00466341e+01  1.00325253e+01 -4.45841805e-04]\n",
      " [ 2.77403329e+01 -9.17083007e-01  7.31004684e-03]\n",
      " [ 1.36239423e-03 -1.71824088e-03 -2.66922294e+00]]\n",
      "[  6.22076522 -33.12257633   3.69206103]\n"
     ]
    }
   ],
   "source": [
    "make_DA_progress_plots(r, np.eye(r), sindy_opt)\n",
    "Q = np.tensordot(sindy_opt.PQ_, Xi, axes=([4, 3], [0, 1]))\n",
    "Q_sum = np.max(np.abs((Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1]))))\n",
    "print(np.max(np.abs(Q_sum)))\n",
    "PC_tensor = np.zeros((r, r, N + 1))\n",
    "for i in range(r):\n",
    "    PC_tensor[i, i, 0] = 1.0\n",
    "print(PC_tensor)\n",
    "m_opt = sindy_opt.m_history_[1]\n",
    "C = np.tensordot(PC_tensor, Xi, axes=([2, 1], [0, 1]))\n",
    "L = np.tensordot(PL_tensor_unsym, Xi, axes=([3, 2], [0, 1]))\n",
    "Q = np.tensordot(PQ_tensor, Xi, axes=([4, 3], [0, 1]))\n",
    "print(Xi[0, :])\n",
    "print(PC_tensor)\n",
    "print(C)\n",
    "print(L)\n",
    "dm = C + np.dot(L, m_opt) + np.dot(np.tensordot(Q, m_opt, axes=([2], [0])), m_opt)\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat $\\alpha \\gg 1$, $\\beta \\ll 1$ case with $\\lambda > 0$\n",
    "I find that solver will fail if eps_solver parameter is made too small (error tolerance of the CVXPY solver is very stringent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "eta = 1.0e2\n",
    "alpha = 1e20\n",
    "beta = 1e-20\n",
    "threshold = 5\n",
    "alpha_m = 9e-1 * eta\n",
    "\n",
    "# run trapping SINDy... no more constraints!\n",
    "sindy_opt = ps.TrappingSR3(\n",
    "    threshold=threshold, eta=eta,\n",
    "    alpha_m=alpha_m,\n",
    "    gamma=-1,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    max_iter=max_iter,\n",
    "    verbose=True,\n",
    "    eps_solver=1e-3\n",
    ")\n",
    "model = ps.SINDy(\n",
    "    optimizer=sindy_opt,\n",
    "    feature_library=sindy_library,\n",
    ")\n",
    "model.fit(x_train, t=t)\n",
    "model.print()\n",
    "Xi = model.coefficients().T\n",
    "PL_tensor = sindy_opt.PL_\n",
    "PQ_tensor = sindy_opt.PQ_\n",
    "Lenergy = np.tensordot(PL_tensor, Xi, axes=([3, 2], [0, 1]))\n",
    "Qenergy = np.tensordot(PQ_tensor, Xi, axes=([4, 3], [0, 1]))\n",
    "mean_val = np.mean(x_test_pred, axis=0)\n",
    "mean_val = np.sqrt(np.sum(mean_val ** 2))\n",
    "check_stability(r, Xi, np.eye(r), sindy_opt, mean_val)\n",
    "Q = np.tensordot(sindy_opt.PQ_, Xi, axes=([4, 3], [0, 1]))\n",
    "print(np.max(np.abs((Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])))))\n",
    "make_progress_plots(r, sindy_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = sindy_opt.PWeigs_history_\n",
    "coef_history = sindy_opt.history_\n",
    "rhos = []\n",
    "for i in range(len(eigs)):\n",
    "    if eigs[i][-1] < 0:\n",
    "        Q = np.tensordot(sindy_opt.PQ_, coef_history[i], axes=([4, 3], [1, 0]))\n",
    "        Q_sum = Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])\n",
    "        # rhos.append(-eigs[i][-1] / (2 * eps_Q))\n",
    "        rhos.append(-eigs[i][-1] / np.max(np.abs(Q_sum)))\n",
    "plt.plot(rhos[1:])\n",
    "plt.grid(True)\n",
    "plt.ylabel('Stability radius')\n",
    "plt.xlabel('Algorithm iteration')\n",
    "plt.show()\n",
    "print(np.max(np.abs(Q_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dysts database contains a number of quadratically nonlinear chaotic systems with the special energy-preserving nonlinear symmetry.\n",
    "You will need to install the dysts database with 'pip install dysts' or similar command (see https://github.com/williamgilpin/dysts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dysts.base import make_trajectory_ensemble\n",
    "from dysts.base import get_attractor_list\n",
    "import dysts.flows as flows\n",
    "import dysts.datasets as datasets\n",
    "from dysts.analysis import sample_initial_conditions\n",
    "from dysts.equation_utils import *\n",
    "\n",
    "def load_data(\n",
    "    systems_list,\n",
    "    all_properties,\n",
    "    n=200,      \n",
    "    pts_per_period=20,\n",
    "    random_bump=False,\n",
    "    include_transients=False,\n",
    "    n_trajectories=20,\n",
    "):      \n",
    "    all_sols_train = dict()\n",
    "    all_sols_test = dict()\n",
    "    all_t_train = dict()\n",
    "    all_t_test = dict()\n",
    "\n",
    "    for i, equation_name in enumerate(systems_list):\n",
    "        eq = getattr(flows, equation_name)()\n",
    "        all_sols_train[equation_name] = []\n",
    "        all_sols_test[equation_name] = []\n",
    "        all_t_train[equation_name] = []\n",
    "        all_t_test[equation_name] = []\n",
    "        print(i, eq)\n",
    "\n",
    "        for j in range(n_trajectories):\n",
    "            ic_train, ic_test = sample_initial_conditions(\n",
    "                eq, 2, traj_length=1000, pts_per_period=30\n",
    "            )\n",
    "\n",
    "            # Kick it off the attractor by random bump with, at most, 1% of the norm of the IC\n",
    "            if random_bump:\n",
    "                ic_train += (np.random.rand(len(ic_train)) - 0.5) * abs(ic_train) / 50\n",
    "                ic_test += (np.random.rand(len(ic_test)) - 0.5) * abs(ic_test) / 50\n",
    "\n",
    "            # Sample at roughly the smallest time scale!!\n",
    "            if include_transients:\n",
    "                pts_per_period = int(1 / (all_properties[equation_name][\"dt\"] * 10))\n",
    "                n = pts_per_period * 10  # sample 10 periods at the largest time scale\n",
    "\n",
    "            eq.ic = ic_train\n",
    "            t_sol, sol = eq.make_trajectory(\n",
    "                n,\n",
    "                pts_per_period=pts_per_period,\n",
    "                resample=True,\n",
    "                return_times=True,\n",
    "                standardize=False,\n",
    "            )\n",
    "            all_sols_train[equation_name].append(sol)\n",
    "            all_t_train[equation_name].append(t_sol)\n",
    "            eq.ic = ic_test\n",
    "            t_sol, sol = eq.make_trajectory(\n",
    "                n,\n",
    "                pts_per_period=pts_per_period,\n",
    "                resample=True,\n",
    "                return_times=True,\n",
    "                standardize=False,\n",
    "            )\n",
    "            all_sols_test[equation_name].append(sol)\n",
    "            all_t_test[equation_name].append(t_sol)\n",
    "    return all_sols_train, all_t_train, all_sols_test, all_t_test\n",
    "\n",
    "\n",
    "# Arneodo does not have the Lyapunov spectrum calculated so omit it.\n",
    "# HindmarshRose and AtmosphericRegime seem to be poorly sampled\n",
    "# by the dt and dominant time scales used in the database, so we omit them.\n",
    "trapping_system_list = np.array([2, 3, 7, 10, 18, 24, 27, 29, 30, 34, 40, 46, 47, 66, 67])\n",
    "systems_list = [\n",
    "                \"Aizawa\", \"Bouali2\", \n",
    "                \"GenesioTesi\", \"HyperBao\", \"HyperCai\", \"HyperJha\", \n",
    "                \"HyperLorenz\", \"HyperLu\", \"HyperPang\", \"Laser\",\n",
    "                \"Lorenz\", \"LorenzBounded\", \"MooreSpiegel\", \"Rossler\", \"ShimizuMorioka\",\n",
    "                \"HenonHeiles\", \"GuckenheimerHolmes\", \"Halvorsen\", \"KawczynskiStrizhak\",\n",
    "                \"VallisElNino\", \"RabinovichFabrikant\", \"NoseHoover\", \"Dadras\", \"RikitakeDynamo\",\n",
    "                \"NuclearQuadrupole\", \"PehlivanWei\", \"SprottTorus\", \"SprottJerk\", \"SprottA\", \"SprottB\",\n",
    "                \"SprottC\", \"SprottD\", \"SprottE\", \"SprottF\", \"SprottG\", \"SprottH\", \"SprottI\", \"SprottJ\",\n",
    "                \"SprottK\", \"SprottL\", \"SprottM\", \"SprottN\", \"SprottO\", \"SprottP\", \"SprottQ\", \"SprottR\",\n",
    "                \"SprottS\", \"Rucklidge\", \"Sakarya\", \"RayleighBenard\", \"Finance\", \"LuChenCheng\",\n",
    "                \"LuChen\", \"QiChen\", \"ZhouChen\", \"BurkeShaw\", \"Chen\", \"ChenLee\", \"WangSun\", \"DequanLi\",\n",
    "                \"NewtonLiepnik\", \"HyperRossler\", \"HyperQi\", \"Qi\", \"LorenzStenflo\", \"HyperYangChen\", \n",
    "                \"HyperYan\", \"HyperXu\", \"HyperWang\", \"Hadley\",\n",
    "               ]\n",
    "alphabetical_sort = np.argsort(systems_list)\n",
    "systems_list = (np.array(systems_list)[alphabetical_sort])[trapping_system_list]\n",
    "\n",
    "# attributes list\n",
    "attributes = [\n",
    "    \"maximum_lyapunov_estimated\",\n",
    "    \"lyapunov_spectrum_estimated\",\n",
    "    \"embedding_dimension\",\n",
    "    \"parameters\",\n",
    "    \"dt\",\n",
    "    \"hamiltonian\",\n",
    "    \"period\",\n",
    "    \"unbounded_indices\"\n",
    "]\n",
    "\n",
    "# Get attributes\n",
    "all_properties = dict()\n",
    "for i, equation_name in enumerate(systems_list):\n",
    "    eq = getattr(flows, equation_name)()\n",
    "    attr_vals = [getattr(eq, item, None) for item in attributes]\n",
    "    all_properties[equation_name] = dict(zip(attributes, attr_vals))\n",
    "    \n",
    "# Get training and testing trajectories for all the experimental systems \n",
    "n = 1000  # Trajectories with 1000 points\n",
    "pts_per_period = 100  # sample them with 100 points per period\n",
    "n_trajectories = 1  # generate 5 trajectories starting from different initial conditions on the attractor\n",
    "all_sols_train, all_t_train, all_sols_test, all_t_test = load_data(\n",
    "    systems_list, all_properties, \n",
    "    n=n, pts_per_period=pts_per_period,\n",
    "    random_bump=False,  # optionally start with initial conditions pushed slightly off the attractor\n",
    "    include_transients=False,  # optionally do high-resolution sampling at rate proportional to the dt parameter \n",
    "    n_trajectories=n_trajectories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attractors = len(systems_list)\n",
    "\n",
    "# Calculate some dynamical properties\n",
    "lyap_list = []\n",
    "dimension_list = []\n",
    "param_list = []\n",
    "\n",
    "# Calculate various definitions of scale separation\n",
    "scale_list_avg = []\n",
    "scale_list = []\n",
    "linear_scale_list = []\n",
    "\n",
    "for system in systems_list:\n",
    "    lyap_list.append(all_properties[system]['maximum_lyapunov_estimated'])\n",
    "    dimension_list.append(all_properties[system]['embedding_dimension'])\n",
    "    param_list.append(all_properties[system]['parameters'])\n",
    "    \n",
    "    # Ratio of dominant (average) to smallest timescales\n",
    "    scale_list_avg.append(all_properties[system]['period'] / all_properties[system]['dt'])\n",
    "\n",
    "\n",
    "# Get the true coefficients for each system\n",
    "true_coefficients = make_dysts_true_coefficients(systems_list, \n",
    "                                                 all_sols_train, \n",
    "                                                 dimension_list, \n",
    "                                                 param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(systems_list)):\n",
    "# define parameters\n",
    "    print(i, systems_list[i])\n",
    "    r = dimension_list[i]\n",
    "    N = int((r ** 2 + 3 * r) / 2.0)\n",
    "    # make training and testing data\n",
    "    t = all_t_train[systems_list[i]][0]\n",
    "    x_train = all_sols_train[systems_list[i]][0]\n",
    "    x_test = all_sols_test[systems_list[i]][0]\n",
    "\n",
    "    # define hyperparameters\n",
    "    threshold = 0\n",
    "    max_iter = 2000\n",
    "    eta = 1.0e3\n",
    "    constraint_zeros, constraint_matrix = make_constraints(r)\n",
    "\n",
    "    alpha_m = 4e-2 * eta  # default is 1e-2 * eta so this speeds up the code here\n",
    "    accel = True  # use acceleration for the update of (m, A), sometimes is faster\n",
    "\n",
    "    # run trapping SINDy\n",
    "    sindy_opt = ps.TrappingSR3(threshold=threshold, eta=eta, alpha_m=alpha_m,\n",
    "                               accel=accel, max_iter=max_iter, gamma=-1,\n",
    "                               constraint_lhs=constraint_matrix,\n",
    "                               constraint_rhs=constraint_zeros,\n",
    "                               constraint_order=\"feature\",\n",
    "                               verbose=True\n",
    "                               )\n",
    "    model = ps.SINDy(\n",
    "        optimizer=sindy_opt,\n",
    "        feature_library=sindy_library,\n",
    "    )\n",
    "    model.fit(x_train, t=t, quiet=True)\n",
    "    model.print()\n",
    "\n",
    "    Xi = model.coefficients().T\n",
    "    Q = np.tensordot(sindy_opt.PQ_, Xi, axes=([4, 3], [0, 1]))\n",
    "    print('nonlinearity preservation breaking = ', np.max(np.abs((Q + np.transpose(Q, [1, 2, 0]) + np.transpose(Q, [2, 0, 1])))))\n",
    "    xdot_test = model.differentiate(x_test, t=t)\n",
    "    xdot_test_pred = model.predict(x_test)\n",
    "    x_train_pred = model.simulate(x_train[0, :], t, integrator_kws=integrator_keywords)\n",
    "    x_test_pred = model.simulate(x_test[0, :], t, integrator_kws=integrator_keywords)\n",
    "    plt.figure(i + 1)\n",
    "    plt.plot(x_train[:, 0], x_train[:, 1])\n",
    "    plt.plot(x_train_pred[:, 0], x_train_pred[:, 1])\n",
    "    check_stability(r, Xi, np.eye(r), sindy_opt, 1.0)\n",
    "    \n",
    "    Xi_true = true_coefficients[i][:, :N + 1].T\n",
    "    boundvals = np.zeros((r, 2))\n",
    "    boundmax = 1000\n",
    "    boundmin = -1000\n",
    "    boundvals[:, 0] = boundmin\n",
    "    boundvals[:, 1] = boundmax\n",
    "\n",
    "    PL_tensor = sindy_opt.PL_\n",
    "    PM_tensor = sindy_opt.PM_\n",
    "    L = np.tensordot(PL_tensor, Xi_true, axes=([3, 2], [0, 1]))\n",
    "    Q = np.tensordot(PM_tensor, Xi_true, axes=([4, 3], [0, 1]))\n",
    "    \n",
    "    # run simulated annealing on the true system to make sure the system is amenable to trapping theorem\n",
    "    algo_sol = anneal_algo(obj_function, bounds=boundvals, \n",
    "                           args=(L, Q, np.eye(r)), \n",
    "                           maxiter=500)\n",
    "    opt_m = algo_sol.x\n",
    "    opt_energy = algo_sol.fun\n",
    "    print('Simulated annealing managed to reduce the largest eigenvalue of A^S to eig1 = ', \n",
    "          opt_energy, '\\n')\n",
    "    print('Optimal m = ', opt_m)\n",
    "#     make_progress_plots(r, sindy_opt)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "f62b9ab411974d02b25bf2f89f4d54b9e7a8fbbc53d424ffba0504d4f9fff406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
